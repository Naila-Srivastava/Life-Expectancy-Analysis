# Life Expectancy Analysis 

Predicting life expectancy using traditional Machine Learning and Deep Learning models, wrapped in a clean Streamlit app for real-time prediction. 

## ğŸ§  Objectives

- To analyze and visualize global health indicators that impact life expectancy.
- To build and evaluate multiple Machine Learning and Deep Learning models to accurately predict life expectancy.
- To deploy an interactive Streamlit app for real-time prediction.
- Predicting the variables that actually affect the life expectancy

## ğŸ”§ Tools & Technologies

- **Python** (`CSV`, `Pandas`, `NumPy`, `Matplotlib`, `Seaborn`, `SciPy`, `Scikit-Learn`, `XGBoost`, `Tensorflow` & `Scikit-Learn`)
- **Streamlit** â€“ For building an interactive web app  
- **Jupyter Notebook** â€“ For code development and EDA  
- **Git & GitHub** â€“ For version control and collaboration 

## ğŸ“‚ Dataset

- The dataset includes various socio-economic and health indicators for countries across years (like GDP, schooling, mortality rates, immunization rates, etc.)
- Due to privacy and size constraints, the full dataset is **not included** in this repository.

â¡ï¸ [Download dataset here](https://www.kaggle.com/datasets/nailasrivastava/life-expectancy-analysis)

## ğŸ’» How to Run

1. Clone the repo  
2. Install dependencies: `pip install -r requirements.txt`  
3. Open the notebooks: `EDA_Life_Expect.ipynb`, `ML_Life_Expect.ipynb` and `DL_Life_Expect.ipynb`  
4. Run all the cells and enjoy the visuals!

## ğŸ¤– Models and their Features

1. Feature Engineering: Outlier detection, Imputation, Normalization
2. Multicollinearity check (VIF) and PCA
3. Machine Learning: Linear Regression, Random Forest, XGBoost (with GridSearchCV)
4. Evaluation Metrics: RÂ² Score, MAE, RMSE, Loss Curves, Validation Loss Tracking
5. Deep Learning: Multi-layered Neural Network using Keras & Tensorflow

## ğŸ§  Model Evaluation Summary

| Model           | RÂ² Score | MAE   | RMSE  |
|-----------------|----------|-------|-------|
| Linear Reg.     | 0.78     | 2.34  | 2.91  |
| Random Forest   | 0.93     | 1.22  | 1.65  |
| XGBoost         | 0.935    | 1.19  | 1.62  |
| Neural Network  | 0.91     | 1.35  | 1.75  |

â¡ï¸ *XGBoost and Random Forest gave the best balance between interpretability and accuracy.*

## ğŸ“Š Key Analysis

- Strong negative correlation between infant mortality, HIV/AIDS prevalence, and life expectancy.
- Positive impact of GDP, schooling, and health expenditure on life expectancy.
- Clear regional clusters in healthcare access and outcomes.

## ğŸ“ˆ Sample Visualizations

- **Correlation Heatmap**- To identify multicollinearity and relationships between features.
- **Distribution Plots**- To understand the skewness, central tendencies, and spread of key variables.
- **Outlier Detection via Boxplots**- Helped shape data preprocessing.
- **Hypothesis Testing (t-tests)**- Checked significance of means across grouped data.
- **Predicted vs Actual Plot**- To evaluate model accuracy.
- **Training & Validation Loss Curves**- For visualizing model convergence and overfitting signs.

## ğŸŒ Advanced Visuals

- Neural Network Training Curves
- Dimensionality Reduction via PCA
- Feature Importance (Random Forest & XGBoost)
- Streamlit Live Inference Interface

## ğŸ“ Key Takeaways

* Socio-economic features like **Schooling**, **GDP**, and **Income Composition** have a **strong positive impact** on life expectancy.
* Health-related indicators such as **Adult Mortality**, **HIV/AIDS**, and **Infant Deaths** show a **strong negative correlation**.
* **Multicollinearity** was found between some features (e.g., infant deaths & under-five deaths), and was addressed using VIF filtering and PCA.
* Ensemble methods like **Random Forest** and **XGBoost** performed **exceptionally well** with minimal tuning.
* **Deep Learning** showed competitive performance after early stopping and validation tuning.
* Visualisations helped uncover **non-obvious relationships**, such as expenditure outliers in some countries with low life expectancy.
* **PCA** was tested for dimensionality reduction but slightly reduced model accuracy.
* Our **Streamlit app** makes the entire model pipeline **accessible for real-time prediction**.
* Deep Learning models showed competitive performance compared to ensemble methods, but simpler models like Random Forest held up surprisingly well.
* PCA didnâ€™t improve prediction but raw engineered features worked best.
* Model deployment adds a practical layer to any predictive analysis project.

## ğŸ§© Whatâ€™s Next?

1. Implement SHAP or LIME for model explainability
2. Add time-series trend analysis (multi-year tracking)
3. Extend app with batch predictions via CSV upload

## ğŸ™Œ Acknowledgments

Huge thanks to the open-source community, and Streamlit for making deployment ridiculously fun.
This project was completed as part of a 12-week Upskilling Sprint (Data Analyst Internship).

Massive gratitude to:
* Deeksha Russell and Duan Wang who collected the dataset from the WHO and the United Nations website.

## ğŸ“‚ Project structure

```plaintext
Life-Expectancy-Analysis/
â”‚
â”œâ”€â”€ app.py                                              # Streamlit application script
â”œâ”€â”€ life_expectancy_model.keras                         # Trained DL model
â”œâ”€â”€ scaler.pkl                                          # Feature scaler object
â”œâ”€â”€ requirements.txt                                    # Dependencies list
â”œâ”€â”€ Life_Expectancy_Data.csv                            # Raw dataset
â”œâ”€â”€ life_expectancy_cleaned_dataset.csv                 # Cleaned dataset
â”œâ”€â”€ new_df.csv                                          # Dataset for ML and Deep Learning analysis 
â”œâ”€â”€ EDA_Life_Expect.ipynb                               # EDA notebook
â”œâ”€â”€ ML_Life_Expect.ipynb                                # Machine Learning notebook
â”œâ”€â”€ DL_Life_Expect.ipynb                                # Deep Learning notebook
â”œâ”€â”€ plots/                                              # Folder for all generated plots
â”œâ”€â”€ README.md                                           # You're reading this now 
â””â”€â”€ .gitignore

